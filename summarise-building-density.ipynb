{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarise building density information\n",
    "\n",
    "Access NISMOD-DB to download building data and summarise regional floor area and footprint density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas\n",
    "import geopandas\n",
    "import requests\n",
    "import shapely.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth():    \n",
    "    # Read connection details\n",
    "    if 'NISMOD_API_USER' in os.environ and 'NISMOD_API_PASSWORD' in os.environ:\n",
    "        username = os.environ['NISMOD_API_USER']\n",
    "        password = os.environ['NISMOD_API_PASSWORD']\n",
    "    else:\n",
    "        parser = configparser.ConfigParser()\n",
    "        parser.read('dbconfig.ini')\n",
    "        username = parser['nismod-api']['user']\n",
    "        password = parser['nismod-api']['password']\n",
    "\n",
    "    return (username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_CODE = 'E06000042'\n",
    "BUILDINGS_YEAR = 2017\n",
    "CACHE_PATH = os.path.join('.', 'db-data')\n",
    "AUTH = get_auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_lad_codes = [\n",
    "    \"E06000031\", \"E06000032\", \"E06000042\", \"E06000055\", \"E06000056\", \"E07000004\", \"E07000005\", \n",
    "    \"E07000006\", \"E07000007\", \"E07000008\", \"E07000009\", \"E07000010\", \"E07000011\", \"E07000012\", \n",
    "    \"E07000150\", \"E07000151\", \"E07000152\", \"E07000153\", \"E07000154\", \"E07000155\", \"E07000156\", \n",
    "    \"E07000177\", \"E07000178\", \"E07000179\", \"E07000180\", \"E07000181\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lads = pandas.read_csv('data_as_provided/arc_dwellings__baseline.csv').lad_uk_2016.unique()\n",
    "lads[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buildings(auth, lad_code, year, force=False):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(CACHE_PATH))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    buildings_file = os.path.join(CACHE_PATH, \"buildings_{}.json\".format(lad_code))\n",
    "\n",
    "    if not os.path.exists(buildings_file) or force:\n",
    "        r = requests.get(\n",
    "            'https://www.nismod.ac.uk/api/data/mastermap/buildings',\n",
    "            auth=auth,\n",
    "            params={\n",
    "                'scale': 'lad',\n",
    "                'area_codes': lad_code,\n",
    "                'building_year': year\n",
    "            },\n",
    "            stream=True\n",
    "        )\n",
    "        with open(buildings_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arc_lad_code in arc_lad_codes:\n",
    "    print(\"Getting\", arc_lad_code)\n",
    "    get_buildings(AUTH, arc_lad_code, BUILDINGS_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for arc_lad_code in arc_lad_codes:\n",
    "    with open(os.path.join(CACHE_PATH, \"buildings_{}.json\".format(arc_lad_code))) as fh:\n",
    "        print(\"Loading\", arc_lad_code)\n",
    "        lad_buildings = json.load(fh)\n",
    "        df = geopandas.GeoDataFrame(lad_buildings)\n",
    "        df.geometry = df.geom.apply(lambda wkt: shapely.wkt.loads(wkt))\n",
    "        dfs.append(df)\n",
    "buildings = pandas.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.floor_area = buildings.floor_area.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.drop(\"geom\" ,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.class_code = buildings.class_code.apply(lambda d: json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.group_ids = buildings.group_ids.apply(lambda d: json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.to_file(\"arc_buildings.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get generic surfaces\n",
    "\n",
    "- could attempt to associate to buildings by adjacency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plots(auth, lad_code, force=False):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(CACHE_PATH))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    buildings_file = os.path.join(CACHE_PATH, \"plots_{}.json\".format(lad_code))\n",
    "\n",
    "    if not os.path.exists(buildings_file) or force:\n",
    "        r = requests.get(\n",
    "            'https://www.nismod.ac.uk/api/data/mastermap/areas',\n",
    "            auth=auth,\n",
    "            params={\n",
    "                'scale': 'lad',\n",
    "                'area_codes': lad_code,\n",
    "                'classification_codes': 'all'\n",
    "            },\n",
    "            stream=True\n",
    "        )\n",
    "        with open(buildings_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arc_lad_code in arc_lad_codes:\n",
    "    print(\"Getting\", arc_lad_code)\n",
    "    get_plots(AUTH, arc_lad_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for arc_lad_code in arc_lad_codes:\n",
    "    with open(os.path.join(CACHE_PATH, \"plots_{}.json\".format(arc_lad_code))) as fh:\n",
    "        df = json.load(fh)\n",
    "        df = geopandas.GeoDataFrame(df)\n",
    "        df.geometry = df.geom.apply(lambda wkt: shapely.wkt.loads(wkt))\n",
    "        df.drop(\"geom\" ,axis=1, inplace=True)\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots = pandas.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots.descriptive_group = lad_plots.descriptive_group.apply(lambda d: json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots.theme = lad_plots.theme.apply(lambda d: json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots.theme.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots.descriptive_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots = lad_plots[lad_plots.descriptive_group == '[\"General Surface\"]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_plots.to_file(\"arc_surfaces.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get land parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parcels(auth, lad_code, force=False):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(CACHE_PATH))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    buildings_file = os.path.join(CACHE_PATH, \"parcels_{}.json\".format(lad_code))\n",
    "\n",
    "    if not os.path.exists(buildings_file) or force:\n",
    "        r = requests.get(\n",
    "            'https://www.nismod.ac.uk/api/data/mastermap/landparcels',\n",
    "            auth=auth,\n",
    "            params={\n",
    "                'scale': 'lad',\n",
    "                'area_codes': lad_code\n",
    "            },\n",
    "            stream=True\n",
    "        )\n",
    "        with open(buildings_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for arc_lad_code in arc_lad_codes:\n",
    "    print(\"Getting\", arc_lad_code)\n",
    "    get_parcels(AUTH, arc_lad_code)\n",
    "    \n",
    "    with open(os.path.join(CACHE_PATH, \"parcels_{}.json\".format(arc_lad_code))) as fh:\n",
    "        df = json.load(fh)\n",
    "        df = geopandas.GeoDataFrame(df)\n",
    "        df.geometry = df.geom.apply(lambda wkt: shapely.wkt.loads(wkt))\n",
    "        df.drop(\"geom\" ,axis=1, inplace=True)\n",
    "        dfs.append(df)\n",
    "parcels = pandas.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels.to_file(\"arc_parcels.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_households(auth, lad_code, year, force=False):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(CACHE_PATH))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    hfile = os.path.join(CACHE_PATH, \"households_{}.json\".format(lad_code))\n",
    "\n",
    "    if not os.path.exists(hfile) or force:\n",
    "        r = requests.get(\n",
    "            'https://www.nismod.ac.uk/api/data/households/households',\n",
    "            auth=auth,\n",
    "            params={\n",
    "                'scale': 'lad',\n",
    "                'area_codes': lad_code,\n",
    "                'year': year\n",
    "            },\n",
    "            stream=True\n",
    "        )\n",
    "        with open(hfile, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for arc_lad_code in arc_lad_codes:\n",
    "    print(\"Getting\", arc_lad_code)\n",
    "    get_households(AUTH, arc_lad_code, BUILDINGS_YEAR)\n",
    "    \n",
    "    with open(os.path.join(CACHE_PATH, \"households_{}.json\".format(arc_lad_code))) as fh:\n",
    "        df = json.load(fh)\n",
    "        df = geopandas.GeoDataFrame(df)\n",
    "        dfs.append(df)\n",
    "households = pandas.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households.to_csv(\"arc_households.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lads_11_not_16 = [\n",
    "    'E06000048',\n",
    "    'E07000100',\n",
    "    'E07000104',\n",
    "    'E07000097',\n",
    "    'E07000101',\n",
    "    'E08000020'\n",
    "]\n",
    "lads = list(lads)\n",
    "lads.extend(lads_11_not_16)\n",
    "lads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for lad_code in lads:\n",
    "    print(\"Getting\", lad_code)\n",
    "    get_households(AUTH, lad_code, BUILDINGS_YEAR)\n",
    "    \n",
    "    with open(os.path.join(CACHE_PATH, \"households_{}.json\".format(lad_code))) as fh:\n",
    "        df = json.load(fh)\n",
    "        df = geopandas.GeoDataFrame(df)\n",
    "        dfs.append(df)\n",
    "all_households = pandas.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_households.to_csv(\"all_households.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join buildings and households (by id)\n",
    "\n",
    "- current data has `None` for `household_id` (buildings) and `hh_id` (households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.household_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households.hh_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(households)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get household assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignments(auth, lad_code, year, force=False):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(CACHE_PATH))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    hfile = os.path.join(CACHE_PATH, \"household_assignments_{}.json\".format(lad_code))\n",
    "\n",
    "    if not os.path.exists(hfile) or force:\n",
    "        r = requests.get(\n",
    "            'https://www.nismod.ac.uk/api/data/assignment/household_assignment',\n",
    "            auth=auth,\n",
    "            params={\n",
    "                'scale': 'lad',\n",
    "                'area_codes': lad_code,\n",
    "                'year': year\n",
    "            },\n",
    "            stream=True\n",
    "        )\n",
    "        with open(hfile, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "dfs = []\n",
    "for arc_lad_code in arc_lad_codes:\n",
    "    print(\"Getting\", arc_lad_code)\n",
    "    get_assignments(AUTH, arc_lad_code, BUILDINGS_YEAR, True)\n",
    "    \n",
    "    with open(os.path.join(CACHE_PATH, \"household_assignments_{}.json\".format(arc_lad_code))) as fh:\n",
    "        df = json.load(fh)\n",
    "        df = geopandas.GeoDataFrame(df)\n",
    "        dfs.append(df)\n",
    "household_assignments = pandas.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df[\n",
    "    ['oa', 'mistral_function_class', 'mistral_building_class', 'floor_area', 'footprint_area', 'res_count']\n",
    "].groupby(\n",
    "    ['oa', 'mistral_function_class', 'mistral_building_class']\n",
    ").sum()\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('summary_arc_buildings_by_oa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lad = df[\n",
    "    ['lad', 'mistral_function_class', 'mistral_building_class', 'floor_area', 'footprint_area', 'res_count']\n",
    "].groupby(\n",
    "    ['lad', 'mistral_function_class', 'mistral_building_class']\n",
    ").sum()\n",
    "summary_lad.to_csv('summary_arc_buildings_by_lad.csv')\n",
    "summary_lad.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
